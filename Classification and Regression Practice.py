# -*- coding: utf-8 -*-
"""Assignment 5

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1UQm5C8cszVvPibzAsre65wFRwWN20rnc
"""

import pandas as pd
import seaborn as sns
import matplotlib.pyplot as plt
from sklearn import preprocessing
df = pd.read_excel("cancer_patients.xlsx", "Sheet1")
print(df.head())
print("\n")
print(df.describe())
print("\n")
print(df.info())
print("\n")
data_numerical_columns = df.select_dtypes(include=["number"])
sns.heatmap(data_numerical_columns.corr(),annot=True)
plt.show()
print("\n")
predictors = df.iloc[:, 0:7]
marker = df["Marker"]

scaler = preprocessing.StandardScaler().fit(predictors)
print('means per column: ',scaler.mean_)
print('variances per column: ',scaler.var_)

"""Question 2:"""

from sklearn.model_selection import train_test_split
from sklearn.linear_model import LinearRegression
from sklearn.metrics import mean_squared_error, r2_score
import pandas as pd
import seaborn as sns
import matplotlib.pyplot as plt
import numpy as np
from sklearn import preprocessing
df = pd.read_excel("cancer_patients.xlsx", "Sheet1")
predictors = df.iloc[:, 0:7]
marker = df["Marker"]
scaler = preprocessing.StandardScaler().fit(predictors)
X = scaler.transform(predictors)
X = np.array(X)
y = marker
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.20, random_state = 2)
regressor = LinearRegression()
regressor.fit (X_train, y_train)
print("Coefficients: \n", regressor.coef_)
print("y-intercept: \n", regressor.intercept_)
y_pred = regressor.predict(X_test)
print("Mean squared error: " , round(mean_squared_error(y_test, y_pred),2))
print("Coefficient of determination: ", round(r2_score(y_test, y_pred),2))
print("The mean squared error is 0, so it is accurate")
print("The r squared value is 1.0 so the regression model is doing a good job at describing the relationship between the inputs and the output")
plt.figure()
plt.scatter(y_test, y_pred, label ='Regression Model')

"""Question 3:"""

from sklearn import tree
from sklearn.tree import DecisionTreeClassifier
from sklearn.model_selection import train_test_split
from sklearn import preprocessing
import pandas as pd
import numpy as np
from sklearn.naive_bayes import GaussianNB
from sklearn.neighbors import KNeighborsClassifier
from sklearn.svm import SVC

df = pd.read_excel ("cancer_patients.xlsx", "Sheet1")
X = df[['Genetic Risk', 'Alcohol use', 'Weight Loss']]
X = np.array(X)
y=df["Cancer"]
y = np.array(y)
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.25, random_state = 10)

clf_dt3 = DecisionTreeClassifier(max_depth=3)
clf_dt3.fit(X_train, y_train)
y_pred = clf_dt3.predict(X_test)
print('Decision Tree (max_depth=3) Accuracy:', round (clf_dt3.score (X_test, y_test), 2))

clf_dt5 = DecisionTreeClassifier(max_depth=5)
clf_dt5.fit(X_train, y_train)
y_pred = clf_dt5.predict(X_test)
print('Decision Tree (max_depth=5) Accuracy::', round (clf_dt5.score (X_test, y_test),2))

clf = GaussianNB()
clf.fit(X_train, y_train)
y_pred = clf.predict(X_test)
print('Naive Bayes Accuracy:', round (clf.score (X_test, y_test), 2))

clf_KNN5 = KNeighborsClassifier(n_neighbors = 5)
clf_KNN5.fit(X_train, y_train)
y_pred = clf_KNN5.predict(X_test)
print('KNN (n_neighbors=5) Accuracy:', round (clf_KNN5.score(X_test, y_test), 2))

clf_KNN10 = KNeighborsClassifier(n_neighbors = 10)
clf_KNN10.fit(X_train, y_train)
y_pred = clf_KNN10.predict(X_test)
print('KNN (n_neighbors=10) Accuracy:', round(clf_KNN10.score (X_test, y_test), 2))

clf_SVM_P = SVC (kernel = 'poly')
clf_SVM_P.fit(X_train, y_train)
y_pred = clf_SVM_P.predict(X_test)
print('SVM (Polynomial Kernel) Accuracy:', round(clf_SVM_P.score (X_test, y_test), 2))

clf_SVM_R = SVC(kernel = 'rbf')
clf_SVM_R.fit(X_train, y_train)
y_pred = clf_SVM_R.predict(X_test)
print('SVM (RBF Kernel) Accuracy:', round(clf_SVM_R.score (X_test, y_test),2))

from sklearn import tree
from sklearn.tree import DecisionTreeClassifier
from sklearn.model_selection import train_test_split
from sklearn import preprocessing
import pandas as pd
import numpy as np
from sklearn. naive_bayes import GaussianNB
from sklearn.neighbors import KNeighborsClassifier
from sklearn.svm import SVC
df = pd.read_excel ("cancer_patients.xlsx", "Sheet1")
X = df [[ 'Age', 'Genetic Risk', 'Alcohol use', 'Obesity', 'Weight Loss', 'Marker']]
X = np.array(X)
y = df ["Cancer"]
y = np.array(y)
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.25, random_state = 10)

clf_dt3 = DecisionTreeClassifier(max_depth=3)
clf_dt3.fit(X_train, y_train)
y_pred = clf_dt3.predict(X_test)
print('Decision Tree (max_depth=3) Accuracy:', round (clf_dt3.score (X_test, y_test), 2))

clf_dt5 = DecisionTreeClassifier(max_depth=5)
clf_dt5.fit(X_train, y_train)
y_pred = clf_dt5.predict(X_test)
print('Decision Tree (max_depth=5) Accuracy:', round (clf_dt5.score (X_test, y_test), 2))

clf = GaussianNB()
clf.fit(X_train, y_train)
y_pred = clf.predict(X_test)
print('Naive Bayes Accuracy:', round(clf.score (X_test, y_test),2))

clf_KNN5 = KNeighborsClassifier (n_neighbors = 5)
clf_KNN5.fit(X_train, y_train)
y_pred = clf_KNN5.predict(X_test)
print('KNN (n_neighbors=5) Accuracy:', round (clf_KNN5.score(X_test, y_test),2))

clf_KNN10 = KNeighborsClassifier(n_neighbors = 10)
clf_KNN10.fit(X_train, y_train)
y_pred = clf_KNN10.predict(X_test)
print('KNN (n_neighbors=10) Accuracy:', round(clf_KNN10.score (X_test, y_test), 2))

clf_SVM_P = SVC (kernel = 'poly')
clf_SVM_P.fit(X_train, y_train)
y_pred = clf_SVM_P.predict(X_test)
print('SVM (Polynomial Kernel) Accuracy:', round (clf_SVM_P.score (X_test, y_test), 2))

clf_SVM_R = SVC(kernel = 'rbf')
clf_SVM_R.fit(X_train, y_train)
y_pred = clf_SVM_R.predict(X_test)
print('SVM (RBF Kernel) Accuracy:', round (clf_SVM_R.score(X_test, y_test),2))

import numpy as np
import matplotlib.pyplot as plt

# Define the parameter t in the range [0, pi/2]
t = np.linspace(0, np.pi / 2, 100)

# Parametric equations
x = np.sin(4 * t)
y = np.cos(4 * t)

# Plot the curve
plt.figure(figsize=(6, 6))
plt.plot(x, y, label=r'$x = \sin(4t), y = \cos(4t)$', color='blue')

# Indicate the direction with arrows
for i in range(0, len(t), 20):
    plt.arrow(x[i], y[i], x[i+1] - x[i], y[i+1] - y[i],
              shape='full', color='red', head_width=0.05, head_length=0.05)

# Set axis limits and labels
plt.axhline(0, color='black', linewidth=0.5)
plt.axvline(0, color='black', linewidth=0.5)
plt.gca().set_aspect('equal', adjustable='box')
plt.xlabel('x')
plt.ylabel('y')
plt.title('Parametric Curve: $x = \sin(4t)$, $y = \cos(4t)$')
plt.legend()
plt.grid(alpha=0.3)
plt.show()